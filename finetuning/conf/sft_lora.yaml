# SFT Training Configuration with LoRA PEFT
training:
  # Model and data settings
  model_name_or_path: "Qwen/Qwen2-Audio-7B-Instruct"
  data_file: "data/train_evalv1-v2/data.jsonl"
  output_dir: "exp/sft_lora"
  
  # Training hyperparameters
  seed: 42
  data_seed: 42
  num_train_epochs: 2
  max_steps: 10000
  per_device_train_batch_size: 8
  gradient_accumulation_steps: 4
  learning_rate: 0.00005
  weight_decay: 0.01
  warmup_steps: 1000
  warmup_ratio: 0.05
  max_grad_norm: 1.0
  
  # Optimization settings
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
  bf16: true
  gradient_checkpointing: true
  
  # Logging and saving
  logging_steps: 1
  save_steps: 2000
  save_only_model: true
  run_name: "ROLE-SFT-LoRA"
  
  # Data loading
  dataloader_num_workers: 4
  dataloader_pin_memory: true
  dataloader_drop_last: true
  remove_unused_columns: false
  group_by_length: false
  length_column_name: "length"
  ignore_data_skip: false
  
  # Reporting
  report_to: []
  use_wandb: false
  
  # DeepSpeed
  deepspeed_config: "conf/ds_zero1.json"

# PEFT Configuration - LoRA
peft:
  enabled: true
  method: "lora"
  
  # LoRA specific settings
  lora:
    r: 16
    lora_alpha: 32
    target_modules: ["q_proj", "v_proj", "k_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
    lora_dropout: 0.1
    bias: "none"
    task_type: "CAUSAL_LM"

# Distributed training settings
distributed:
  gpu_num: 2
  node_num: 1
  node_rank: 0
  master_addr: "127.0.0.1"
  master_port: 32777 
